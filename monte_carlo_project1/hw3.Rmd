---
title:  | 
  | \vspace{0.5cm} \LARGE{Monte Carlo Methods for Optimization}
  | \vspace{0.5cm} \Large{Project 1}
author: "XUAN HUYNH"
date: "4/16/2020"
output: pdf_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=F, message=F)
```
## Question 1
### Part a)
Before running the experiment, I supposed that the alternative 3 would be more efficient since the overlapped area between the sample space formed with the orignal distribution $\pi(x)$ and the sample space formed with g(x,y) and $\sigma_0 = 4$ is larger than that with $\sigma_0 = 1$. From the given visualization of the distributions, we can observe that the larger the variance of g(x) (with the given fixed means), the larger the overlapped area.

From the convergence plot, obviously, $\hat\theta$ converges the fastest with samples drawn from the true distribution ($\hat\theta_1$), followed by $\hat\theta_3$ and $\hat\theta_2$. $\hat\theta_2$ does not seem to converge until sample size of $10^5$ while $\hat\theta_3$ starts to converge at sample size of $10^3$.

![](/Users/andrewchang/Desktop/STAT 202C/Week3/1a.png){#id .class width=80% height=60%}

### Part b)

In this part we estimate the "effective sample size" for each alternative and assess how good this approximation to $ess^{\ast}(n)$ is. Since the samples in Alternative 1 are each “effective” samples of size 1 as they are directly drawn from the target distribution, we use $ess^{\ast}(n_1)=n_1$ as the truth and compare the effective sample sizes for Alternative 2 and Alternative 3 to Alternative 1.

It can be seen from both of the the following plots that the suggested formula for estimating the effective sample size is almost consistently overestmiating the true value. In both plots, the orange line (estimated effective sample size) stays above the blue line (true effective sample size), but for Alternative 3, the effective sample size curves seem to increase smoothly as sample size increases. Also, for a given actual sample size (the x-axis), the effective sample size (both true and estimated) of Alternative 2 is a lot smaller the actual sample size  while this difference is less severe for Alternative 3. This means that sampling with Alternative 3 is more efficient than Alternative 2.

![](/Users/andrewchang/Desktop/STAT 202C/Week3/1b1.png){#id .class width=80% height=60%}

![](/Users/andrewchang/Desktop/STAT 202C/Week3/1b2.png){#id .class width=80% height=60%}


The next two plots show what we already noted in the previous part: the lines $ess^{\ast}_3(n)$ and $ess_3(n)$ smoothly move upward, but this cannot be seen in $ess^{\ast}_2(n)$ against $ess_2(n)$ plot.

![](/Users/andrewchang/Desktop/STAT 202C/Week3/1b3.png){#id .class width=80% height=60%}

![](/Users/andrewchang/Desktop/STAT 202C/Week3/1b4.png){#id .class width=80% height=60%}

## Question 2

# Part a) Estimate number of Self-Avoiding-Walk with-in a grid of size $11\times 11$


![](/Users/andrewchang/Desktop/STAT 202C/Week3/2a.png){#id .class width=80% height=90%}

__Design 1__: K = 3.316510848426416e+25 SAW's. In this design, we construct a simple self-avoiding-walk, meaning at each step, we randomly choose a feasible location to walk to.  
__Design 2__: K = 3.667548256985243e+25 SAW's. This design favors shorter walks. For all walks that are longer than 75 steps, we introduce another "location" to walk to: "terminate early". The probability to terminate early in this experiment is set at 0.1, and the remaining 0.9 probability is equally distributed to the other feasible locations to choose from at each step.   
__Design 3__: K = 2.9726468730832277e+25 SAW's. Design 3, in contrast, favors longer walks. For each walk that reaches length of 90, we generate 5 more walks continuing from step 90. 

# Part b) Estimate number of Self-Avoiding-Walk with-in a grid of size $11\times 11$ that ends at (10,10)
In this part, we try estimating the number of SAW's that ends at (10,10) using the first design. The estimated K is 1.1503721130430365e+25, roughly 10 times larger than the true number $1.5687\times10^{24}$. This shows that designing the probability p(r) is very important in using Monte Carlo method for estimating.

# Part c) Distribution of lengths

In this part, we plot the histogram of SAW lengths for each design, with design 1-3 being the ones in part a, and design 4 is the one in part b. To graph these histograms, we have to take into account the weight of each of the SAWs that have the same length. For design 1, it seems like we have more values at the middle area of histogram and less values towards the two sides. This represents a roughly normal distribution. Intuitively, since we do not enforce our preference of a certain length on the design, the lengths should follow a Gaussian distribution (i.e. a walk is less like likely to get stuck too early or has a huge length).  
Design 2 favors shorter walks by introducing the "terminate" choice at each step for walks that are longer than 75 steps. This reflects on the histogram as the values cluster around 75-95 range. For Design 3, which prefers longer walks, it seems like the histogram is left-skewed as more values fall in the 90-100 range. In design 4, we only compute K for those ends at (10,10). Its heavily left-skewed histogram shows that it is more likely to end at (10,10) with longer walks. However, we should also notice that the histogram does not contain many values that pass 90 since the longest walks very likely do not just stop at (10,10).

![](/Users/andrewchang/Desktop/STAT 202C/Week3/2c.png){#id .class width=80% height=60%}

![](/Users/andrewchang/Desktop/STAT 202C/Week3/longest1.png){#id .class width=60% height=60%}

![](/Users/andrewchang/Desktop/STAT 202C/Week3/longest2.png){#id .class width=60% height=60%}

![](/Users/andrewchang/Desktop/STAT 202C/Week3/longest3.png){#id .class width=60% height=60%}

![](/Users/andrewchang/Desktop/STAT 202C/Week3/longest4.png){#id .class width=60% height=60%}
